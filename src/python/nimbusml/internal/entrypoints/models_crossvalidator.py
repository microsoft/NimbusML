# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Models.CrossValidator
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def models_crossvalidator(
        data,
        nodes,
        inputs_subgraph,
        outputs_subgraph,
        predictor_model,
        warnings=None,
        overall_metrics=None,
        per_instance_metrics=None,
        confusion_matrix=None,
        transform_model=None,
        stratification_column=None,
        num_folds=2,
        kind='SignatureBinaryClassifierTrainer',
        label_column='Label',
        weight_column='Weight',
        group_column='GroupId',
        name_column='Name',
        **params):
    """
    **Description**
        Cross validation for general learning

    :param data: The data set (inputs).
    :param transform_model: The transform model from the pipeline
        before this command. It gets included in the
        Output.PredictorModel. (inputs).
    :param nodes: The training subgraph (inputs).
    :param inputs_subgraph: The training subgraph inputs (inputs).
    :param outputs_subgraph: The training subgraph outputs (inputs).
    :param stratification_column: Column to use for stratification
        (inputs).
    :param num_folds: Number of folds in k-fold cross-validation
        (inputs).
    :param kind: Specifies the trainer kind, which determines the
        evaluator to be used. (inputs).
    :param label_column: Column to use for labels (inputs).
    :param weight_column: Column to use for example weight (inputs).
    :param group_column: Column to use for grouping (inputs).
    :param name_column: Name column name (inputs).
    :param predictor_model: The final model including the trained
        predictor model and the model from the transforms, provided
        as the Input.TransformModel. (outputs).
    :param warnings: Warning dataset (outputs).
    :param overall_metrics: Overall metrics dataset (outputs).
    :param per_instance_metrics: Per instance metrics dataset
        (outputs).
    :param confusion_matrix: Confusion matrix dataset (outputs).
    """

    entrypoint_name = 'Models.CrossValidator'
    inputs = {}
    outputs = {}

    if data is not None:
        inputs['Data'] = try_set(
            obj=data,
            none_acceptable=False,
            is_of_type=str)
    if transform_model is not None:
        inputs['TransformModel'] = try_set(
            obj=transform_model,
            none_acceptable=True,
            is_of_type=str)
    if nodes is not None:
        inputs['Nodes'] = try_set(
            obj=nodes,
            none_acceptable=False,
            is_of_type=list)
    if inputs_subgraph is not None:
        inputs['Inputs'] = try_set(
            obj=inputs_subgraph,
            none_acceptable=False,
            is_of_type=dict,
            field_names=['Data'])
    if outputs_subgraph is not None:
        inputs['Outputs'] = try_set(
            obj=outputs_subgraph,
            none_acceptable=False,
            is_of_type=dict,
            field_names=['PredictorModel'])
    if stratification_column is not None:
        inputs['StratificationColumn'] = try_set(
            obj=stratification_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if num_folds is not None:
        inputs['NumFolds'] = try_set(
            obj=num_folds,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if kind is not None:
        inputs['Kind'] = try_set(
            obj=kind,
            none_acceptable=False,
            is_of_type=str,
            values=[
                'SignatureBinaryClassifierTrainer',
                'SignatureMulticlassClassificationTrainer',
                'SignatureRankerTrainer',
                'SignatureRegressorTrainer',
                'SignatureMultiOutputRegressorTrainer',
                'SignatureAnomalyDetectorTrainer',
                'SignatureClusteringTrainer'])
    if label_column is not None:
        inputs['LabelColumn'] = try_set(
            obj=label_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if weight_column is not None:
        inputs['WeightColumn'] = try_set(
            obj=weight_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if group_column is not None:
        inputs['GroupColumn'] = try_set(
            obj=group_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if name_column is not None:
        inputs['NameColumn'] = try_set(
            obj=name_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if predictor_model is not None:
        outputs['PredictorModel'] = try_set(
            obj=predictor_model,
            none_acceptable=False,
            is_of_type=list)
    if warnings is not None:
        outputs['Warnings'] = try_set(
            obj=warnings, none_acceptable=False, is_of_type=str)
    if overall_metrics is not None:
        outputs['OverallMetrics'] = try_set(
            obj=overall_metrics, none_acceptable=False, is_of_type=str)
    if per_instance_metrics is not None:
        outputs['PerInstanceMetrics'] = try_set(
            obj=per_instance_metrics, none_acceptable=False, is_of_type=str)
    if confusion_matrix is not None:
        outputs['ConfusionMatrix'] = try_set(
            obj=confusion_matrix, none_acceptable=False, is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
