# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Transforms.NGramTranslator
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def transforms_ngramtranslator(
        data,
        output_data=None,
        model=None,
        column=None,
        ngram_length=2,
        all_lengths=True,
        skip_length=0,
        max_num_terms=[10000000],
        weighting='Tf',
        **params):
    """
    **Description**
        Produces a bag of counts of n-grams (sequences of consecutive values
        of length 1-n) in a given vector of keys. It does so by
        building a dictionary of n-grams and using the id in the
        dictionary as the index in the bag.

    :param column: New column definition(s) (optional form: name:src)
        (inputs).
    :param data: Input dataset (inputs).
    :param ngram_length: Maximum n-gram length (inputs).
    :param all_lengths: Whether to store all n-gram lengths up to
        ngramLength, or only ngramLength (inputs).
    :param skip_length: Maximum number of tokens to skip when
        constructing an n-gram (inputs).
    :param max_num_terms: Maximum number of n-grams to store in the
        dictionary (inputs).
    :param weighting: The weighting criteria (inputs).
    :param output_data: Transformed dataset (outputs).
    :param model: Transform model (outputs).
    """

    entrypoint_name = 'Transforms.NGramTranslator'
    inputs = {}
    outputs = {}

    if column is not None:
        inputs['Column'] = try_set(
            obj=column,
            none_acceptable=True,
            is_of_type=list,
            is_column=True)
    if data is not None:
        inputs['Data'] = try_set(
            obj=data,
            none_acceptable=False,
            is_of_type=str)
    if ngram_length is not None:
        inputs['NgramLength'] = try_set(
            obj=ngram_length,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if all_lengths is not None:
        inputs['AllLengths'] = try_set(
            obj=all_lengths,
            none_acceptable=True,
            is_of_type=bool)
    if skip_length is not None:
        inputs['SkipLength'] = try_set(
            obj=skip_length,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if max_num_terms is not None:
        inputs['MaxNumTerms'] = try_set(
            obj=max_num_terms,
            none_acceptable=True,
            is_of_type=list)
    if weighting is not None:
        inputs['Weighting'] = try_set(
            obj=weighting,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'Tf',
                'Idf',
                'TfIdf'])
    if output_data is not None:
        outputs['OutputData'] = try_set(
            obj=output_data,
            none_acceptable=False,
            is_of_type=str)
    if model is not None:
        outputs['Model'] = try_set(
            obj=model,
            none_acceptable=False,
            is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
