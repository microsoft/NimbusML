# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Trainers.FieldAwareFactorizationMachineBinaryClassifier
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def trainers_fieldawarefactorizationmachinebinaryclassifier(
        training_data,
        predictor_model=None,
        learning_rate=0.1,
        number_of_iterations=5,
        feature_column_name='Features',
        latent_dimension=20,
        label_column_name='Label',
        lambda_linear=0.0001,
        example_weight_column_name=None,
        lambda_latent=0.0001,
        normalize_features=True,
        caching='Auto',
        extra_feature_columns=None,
        shuffle=True,
        verbose=True,
        radius=0.5,
        **params):
    """
    **Description**
        Train a field-aware factorization machine for binary classification

    :param learning_rate: Initial learning rate (inputs).
    :param training_data: The data to be used for training (inputs).
    :param number_of_iterations: Number of training iterations
        (inputs).
    :param feature_column_name: Column to use for features (inputs).
    :param latent_dimension: Latent space dimension (inputs).
    :param label_column_name: Column to use for labels (inputs).
    :param lambda_linear: Regularization coefficient of linear
        weights (inputs).
    :param example_weight_column_name: Column to use for example
        weight (inputs).
    :param lambda_latent: Regularization coefficient of latent
        weights (inputs).
    :param normalize_features: Whether to normalize the input vectors
        so that the concatenation of all fields' feature vectors is
        unit-length (inputs).
    :param caching: Whether trainer should cache input training data
        (inputs).
    :param extra_feature_columns: Extra columns to use for feature
        vectors. The i-th specified string denotes the column
        containing features form the (i+1)-th field. Note that the
        first field is specified by "feat" instead of "exfeat".
        (inputs).
    :param shuffle: Whether to shuffle for each training iteration
        (inputs).
    :param verbose: Report traning progress or not (inputs).
    :param radius: Radius of initial latent factors (inputs).
    :param predictor_model: The trained model (outputs).
    """

    entrypoint_name = 'Trainers.FieldAwareFactorizationMachineBinaryClassifier'
    inputs = {}
    outputs = {}

    if learning_rate is not None:
        inputs['LearningRate'] = try_set(
            obj=learning_rate,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if training_data is not None:
        inputs['TrainingData'] = try_set(
            obj=training_data,
            none_acceptable=False,
            is_of_type=str)
    if number_of_iterations is not None:
        inputs['NumberOfIterations'] = try_set(
            obj=number_of_iterations,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if feature_column_name is not None:
        inputs['FeatureColumnName'] = try_set(
            obj=feature_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if latent_dimension is not None:
        inputs['LatentDimension'] = try_set(
            obj=latent_dimension,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if label_column_name is not None:
        inputs['LabelColumnName'] = try_set(
            obj=label_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if lambda_linear is not None:
        inputs['LambdaLinear'] = try_set(
            obj=lambda_linear,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if example_weight_column_name is not None:
        inputs['ExampleWeightColumnName'] = try_set(
            obj=example_weight_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if lambda_latent is not None:
        inputs['LambdaLatent'] = try_set(
            obj=lambda_latent,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if normalize_features is not None:
        inputs['NormalizeFeatures'] = try_set(
            obj=normalize_features, none_acceptable=True, is_of_type=bool)
    if caching is not None:
        inputs['Caching'] = try_set(
            obj=caching,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'Auto',
                'Memory',
                'None'])
    if extra_feature_columns is not None:
        inputs['ExtraFeatureColumns'] = try_set(
            obj=extra_feature_columns,
            none_acceptable=True,
            is_of_type=list,
            is_column=True)
    if shuffle is not None:
        inputs['Shuffle'] = try_set(
            obj=shuffle,
            none_acceptable=True,
            is_of_type=bool)
    if verbose is not None:
        inputs['Verbose'] = try_set(
            obj=verbose,
            none_acceptable=True,
            is_of_type=bool)
    if radius is not None:
        inputs['Radius'] = try_set(
            obj=radius,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if predictor_model is not None:
        outputs['PredictorModel'] = try_set(
            obj=predictor_model, none_acceptable=False, is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
