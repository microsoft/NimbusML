# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Trainers.EnsembleRegression
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist
from ._ensemblesubsetselector_bootstrapselector import bootstrap_selector


def trainers_ensembleregression(
        training_data,
        predictor_model=None,
        sampling_type=bootstrap_selector(
            feature_selector={
                'Name': 'AllFeatureSelector'}),
        feature_column_name='Features',
        num_models=None,
        label_column_name='Label',
        sub_model_selector_type=None,
        output_combiner=None,
        normalize_features='Auto',
        caching='Auto',
        train_parallel=False,
        batch_size=-1,
        show_metrics=False,
        **params):
    """
    **Description**
        Train regression ensemble.

    :param training_data: The data to be used for training (inputs).
    :param sampling_type: Sampling Type (inputs).
    :param feature_column_name: Column to use for features (inputs).
    :param num_models: Number of models per batch. If not specified,
        will default to 50 if there is only one base predictor, or
        the number of base predictors otherwise. (inputs).
    :param label_column_name: Column to use for labels (inputs).
    :param sub_model_selector_type: Algorithm to prune the base
        learners for selective Ensemble (inputs).
    :param output_combiner: Output combiner (inputs).
    :param normalize_features: Normalize option for the feature
        column (inputs).
    :param caching: Whether trainer should cache input training data
        (inputs).
    :param train_parallel: All the base learners will run
        asynchronously if the value is true (inputs).
    :param batch_size: Batch size (inputs).
    :param show_metrics: True, if metrics for each model need to be
        evaluated and shown in comparison table. This is done by
        using validation set if available or the training set
        (inputs).
    :param predictor_model: The trained model (outputs).
    """

    entrypoint_name = 'Trainers.EnsembleRegression'
    inputs = {}
    outputs = {}

    if training_data is not None:
        inputs['TrainingData'] = try_set(
            obj=training_data,
            none_acceptable=False,
            is_of_type=str)
    if sampling_type is not None:
        inputs['SamplingType'] = try_set(
            obj=sampling_type,
            none_acceptable=True,
            is_of_type=dict)
    if feature_column_name is not None:
        inputs['FeatureColumnName'] = try_set(
            obj=feature_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if num_models is not None:
        inputs['NumModels'] = try_set(
            obj=num_models,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if label_column_name is not None:
        inputs['LabelColumnName'] = try_set(
            obj=label_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if sub_model_selector_type is not None:
        inputs['SubModelSelectorType'] = try_set(
            obj=sub_model_selector_type,
            none_acceptable=True,
            is_of_type=dict)
    if output_combiner is not None:
        inputs['OutputCombiner'] = try_set(
            obj=output_combiner,
            none_acceptable=True,
            is_of_type=dict)
    if normalize_features is not None:
        inputs['NormalizeFeatures'] = try_set(
            obj=normalize_features,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'No',
                'Warn',
                'Auto',
                'Yes'])
    if caching is not None:
        inputs['Caching'] = try_set(
            obj=caching,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'Auto',
                'Memory',
                'None'])
    if train_parallel is not None:
        inputs['TrainParallel'] = try_set(
            obj=train_parallel,
            none_acceptable=True,
            is_of_type=bool)
    if batch_size is not None:
        inputs['BatchSize'] = try_set(
            obj=batch_size,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if show_metrics is not None:
        inputs['ShowMetrics'] = try_set(
            obj=show_metrics,
            none_acceptable=True,
            is_of_type=bool)
    if predictor_model is not None:
        outputs['PredictorModel'] = try_set(
            obj=predictor_model, none_acceptable=False, is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
