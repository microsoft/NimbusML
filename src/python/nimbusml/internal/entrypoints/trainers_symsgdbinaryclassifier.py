# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Trainers.SymSgdBinaryClassifier
"""

import numbers

from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def trainers_symsgdbinaryclassifier(
        training_data,
        predictor_model=None,
        feature_column_name='Features',
        label_column_name='Label',
        normalize_features='Auto',
        caching='Auto',
        number_of_iterations=50,
        learning_rate=None,
        l2_regularization=0.0,
        number_of_threads=None,
        tolerance=0.0001,
        update_frequency=None,
        memory_size=1024,
        shuffle=True,
        positive_instance_weight=1.0,
        **params):
    """
    **Description**
        Train a symbolic SGD.

    :param training_data: The data to be used for training (inputs).
    :param feature_column_name: Column to use for features (inputs).
    :param label_column_name: Column to use for labels (inputs).
    :param normalize_features: Normalize option for the feature
        column (inputs).
    :param caching: Whether trainer should cache input training data
        (inputs).
    :param number_of_iterations: Number of passes over the data.
        (inputs).
    :param learning_rate: Learning rate (inputs).
    :param l2_regularization: L2 regularization (inputs).
    :param number_of_threads: Degree of lock-free parallelism.
        Determinism not guaranteed. Multi-threading is not supported
        currently. (inputs).
    :param tolerance: Tolerance for difference in average loss in
        consecutive passes. (inputs).
    :param update_frequency: The number of iterations each thread
        learns a local model until combining it with the global
        model. Low value means more updated global model and high
        value means less cache traffic. (inputs).
    :param memory_size: The acceleration memory budget in MB
        (inputs).
    :param shuffle: Shuffle data? (inputs).
    :param positive_instance_weight: Apply weight to the positive
        class, for imbalanced data (inputs).
    :param predictor_model: The trained model (outputs).
    """

    entrypoint_name = 'Trainers.SymSgdBinaryClassifier'
    inputs = {}
    outputs = {}

    if training_data is not None:
        inputs['TrainingData'] = try_set(
            obj=training_data,
            none_acceptable=False,
            is_of_type=str)
    if feature_column_name is not None:
        inputs['FeatureColumnName'] = try_set(
            obj=feature_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if label_column_name is not None:
        inputs['LabelColumnName'] = try_set(
            obj=label_column_name,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if normalize_features is not None:
        inputs['NormalizeFeatures'] = try_set(
            obj=normalize_features,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'No',
                'Warn',
                'Auto',
                'Yes'])
    if caching is not None:
        inputs['Caching'] = try_set(
            obj=caching,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'Auto',
                'Memory',
                'None'])
    if number_of_iterations is not None:
        inputs['NumberOfIterations'] = try_set(
            obj=number_of_iterations,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if learning_rate is not None:
        inputs['LearningRate'] = try_set(
            obj=learning_rate,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if l2_regularization is not None:
        inputs['L2Regularization'] = try_set(
            obj=l2_regularization,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if number_of_threads is not None:
        inputs['NumberOfThreads'] = try_set(
            obj=number_of_threads,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if tolerance is not None:
        inputs['Tolerance'] = try_set(
            obj=tolerance,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if update_frequency is not None:
        inputs['UpdateFrequency'] = try_set(
            obj=update_frequency,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if memory_size is not None:
        inputs['MemorySize'] = try_set(
            obj=memory_size,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if shuffle is not None:
        inputs['Shuffle'] = try_set(
            obj=shuffle,
            none_acceptable=True,
            is_of_type=bool)
    if positive_instance_weight is not None:
        inputs['PositiveInstanceWeight'] = try_set(
            obj=positive_instance_weight,
            none_acceptable=True,
            is_of_type=numbers.Real)
    if predictor_model is not None:
        outputs['PredictorModel'] = try_set(
            obj=predictor_model, none_acceptable=False, is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
