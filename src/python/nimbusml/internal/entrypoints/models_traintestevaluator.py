# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Models.TrainTestEvaluator
"""


from ..utils.entrypoints import EntryPoint
from ..utils.utils import try_set, unlist


def models_traintestevaluator(
        training_data,
        testing_data,
        nodes,
        inputs_subgraph=0,
        outputs_subgraph=0,
        predictor_model=None,
        warnings=None,
        overall_metrics=None,
        per_instance_metrics=None,
        confusion_matrix=None,
        training_warnings=None,
        training_overall_metrics=None,
        training_per_instance_metrics=None,
        training_confusion_matrix=None,
        transform_model=None,
        kind='SignatureBinaryClassifierTrainer',
        pipeline_id=None,
        include_training_metrics=False,
        label_column='Label',
        weight_column='Weight',
        group_column='GroupId',
        name_column='Name',
        **params):
    """
    **Description**
        General train test for any supported evaluator

    :param training_data: The data to be used for training (inputs).
    :param testing_data: The data to be used for testing (inputs).
    :param transform_model: The aggregated transform model from the
        pipeline before this command, to apply to the test data, and
        also include in the final model, together with the predictor
        model. (inputs).
    :param nodes: The training subgraph (inputs).
    :param inputs_subgraph: The training subgraph inputs (inputs).
    :param outputs_subgraph: The training subgraph outputs (inputs).
    :param kind: Specifies the trainer kind, which determines the
        evaluator to be used. (inputs).
    :param pipeline_id: Identifies which pipeline was run for this
        train test. (inputs).
    :param include_training_metrics: Indicates whether to include and
        output training dataset metrics. (inputs).
    :param label_column: Column to use for labels (inputs).
    :param weight_column: Column to use for example weight (inputs).
    :param group_column: Column to use for grouping (inputs).
    :param name_column: Name column name (inputs).
    :param predictor_model: The final model including the trained
        predictor model and the model from the transforms, provided
        as the Input.TransformModel. (outputs).
    :param warnings: Warning dataset (outputs).
    :param overall_metrics: Overall metrics dataset (outputs).
    :param per_instance_metrics: Per instance metrics dataset
        (outputs).
    :param confusion_matrix: Confusion matrix dataset (outputs).
    :param training_warnings: Warning dataset for training (outputs).
    :param training_overall_metrics: Overall metrics dataset for
        training (outputs).
    :param training_per_instance_metrics: Per instance metrics
        dataset for training (outputs).
    :param training_confusion_matrix: Confusion matrix dataset for
        training (outputs).
    """

    entrypoint_name = 'Models.TrainTestEvaluator'
    inputs = {}
    outputs = {}

    if training_data is not None:
        inputs['TrainingData'] = try_set(
            obj=training_data,
            none_acceptable=False,
            is_of_type=str)
    if testing_data is not None:
        inputs['TestingData'] = try_set(
            obj=testing_data,
            none_acceptable=False,
            is_of_type=str)
    if transform_model is not None:
        inputs['TransformModel'] = try_set(
            obj=transform_model,
            none_acceptable=True,
            is_of_type=str)
    if nodes is not None:
        inputs['Nodes'] = try_set(
            obj=nodes,
            none_acceptable=False,
            is_of_type=list)
    if inputs_subgraph is not None:
        inputs['Inputs'] = try_set(
            obj=inputs_subgraph,
            none_acceptable=False,
            is_of_type=dict,
            field_names=['Data'])
    if outputs_subgraph is not None:
        inputs['Outputs'] = try_set(
            obj=outputs_subgraph,
            none_acceptable=False,
            is_of_type=dict,
            field_names=['PredictorModel'])
    if kind is not None:
        inputs['Kind'] = try_set(
            obj=kind,
            none_acceptable=True,
            is_of_type=str,
            values=[
                'SignatureBinaryClassifierTrainer',
                'SignatureMulticlassClassificationTrainer',
                'SignatureRankerTrainer',
                'SignatureRegressorTrainer',
                'SignatureMultiOutputRegressorTrainer',
                'SignatureAnomalyDetectorTrainer',
                'SignatureClusteringTrainer'])
    if pipeline_id is not None:
        inputs['PipelineId'] = try_set(
            obj=pipeline_id,
            none_acceptable=True,
            is_of_type=str)
    if include_training_metrics is not None:
        inputs['IncludeTrainingMetrics'] = try_set(
            obj=include_training_metrics,
            none_acceptable=True,
            is_of_type=bool)
    if label_column is not None:
        inputs['LabelColumn'] = try_set(
            obj=label_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if weight_column is not None:
        inputs['WeightColumn'] = try_set(
            obj=weight_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if group_column is not None:
        inputs['GroupColumn'] = try_set(
            obj=group_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if name_column is not None:
        inputs['NameColumn'] = try_set(
            obj=name_column,
            none_acceptable=True,
            is_of_type=str,
            is_column=True)
    if predictor_model is not None:
        outputs['PredictorModel'] = try_set(
            obj=predictor_model, none_acceptable=False, is_of_type=str)
    if warnings is not None:
        outputs['Warnings'] = try_set(
            obj=warnings, none_acceptable=False, is_of_type=str)
    if overall_metrics is not None:
        outputs['OverallMetrics'] = try_set(
            obj=overall_metrics, none_acceptable=False, is_of_type=str)
    if per_instance_metrics is not None:
        outputs['PerInstanceMetrics'] = try_set(
            obj=per_instance_metrics, none_acceptable=False, is_of_type=str)
    if confusion_matrix is not None:
        outputs['ConfusionMatrix'] = try_set(
            obj=confusion_matrix, none_acceptable=False, is_of_type=str)
    if training_warnings is not None:
        outputs['TrainingWarnings'] = try_set(
            obj=training_warnings, none_acceptable=False, is_of_type=str)
    if training_overall_metrics is not None:
        outputs['TrainingOverallMetrics'] = try_set(
            obj=training_overall_metrics,
            none_acceptable=False,
            is_of_type=str)
    if training_per_instance_metrics is not None:
        outputs['TrainingPerInstanceMetrics'] = try_set(
            obj=training_per_instance_metrics,
            none_acceptable=False,
            is_of_type=str)
    if training_confusion_matrix is not None:
        outputs['TrainingConfusionMatrix'] = try_set(
            obj=training_confusion_matrix,
            none_acceptable=False,
            is_of_type=str)

    input_variables = {
        x for x in unlist(inputs.values())
        if isinstance(x, str) and x.startswith("$")}
    output_variables = {
        x for x in unlist(outputs.values())
        if isinstance(x, str) and x.startswith("$")}

    entrypoint = EntryPoint(
        name=entrypoint_name, inputs=inputs, outputs=outputs,
        input_variables=input_variables,
        output_variables=output_variables)
    return entrypoint
