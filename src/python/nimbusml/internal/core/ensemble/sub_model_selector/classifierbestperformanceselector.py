# --------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------------------------------------
# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
ClassifierBestPerformanceSelector
"""

__all__ = ["ClassifierBestPerformanceSelector"]

import numbers

from ....utils.entrypoints import Component
from ....utils.utils import trace, try_set


class ClassifierBestPerformanceSelector(Component):
    """

    **Description**
    Combines only the models with the best performance.


    :param metric_name: the metric type to be used to find the weights for
        each model. Can be ``"AccuracyMicro"``, ``"AccuracyMacro"``,
        ``"LogLoss"``, or ``"LogLossReduction"``.

    :param learners_selection_proportion: The proportion of best base learners
        to be selected. The range is 0.0-1.0.

    :param validation_dataset_proportion: The proportion of instances to be
        selected to test the individual base learner. If it is 0, it uses
        training set.

    :param params: Additional arguments sent to compute engine.

    .. seealso::
        :py:class:`EnsembleClassifier
        <nimbusml.ensemble.EnsembleClassifier>`

        * Submodel selectors:
        :py:class:`ClassifierAllSelector
        <nimbusml.ensemble.sub_model_selector.ClassifierAllSelector>`,
        :py:class:`ClassifierBestDiverseSelector
        <nimbusml.ensemble.sub_model_selector.ClassifierBestDiverseSelector>`

        * Output combiners:
        :py:class:`ClassifierAverage
        <nimbusml.ensemble.output_combiner.ClassifierAverage>`,
        :py:class:`ClassifierMedian
        <nimbusml.ensemble.output_combiner.ClassifierMedian>`,
        :py:class:`ClassifierStacking
        <nimbusml.ensemble.output_combiner.ClassifierStacking>`,
        :py:class:`ClassifierVoting
        <nimbusml.ensemble.output_combiner.ClassifierVoting>`


    .. index:: models, ensemble, classification

    """

    @trace
    def __init__(
            self,
            metric_name='AccuracyMicro',
            learners_selection_proportion=0.5,
            validation_dataset_proportion=0.3,
            **params):

        self.metric_name = metric_name
        self.learners_selection_proportion = learners_selection_proportion
        self.validation_dataset_proportion = validation_dataset_proportion
        self.kind = 'EnsembleMulticlassSubModelSelector'
        self.name = 'BestPerformanceSelectorMultiClass'
        self.settings = {}

        if metric_name is not None:
            self.settings['MetricName'] = try_set(
                obj=metric_name, none_acceptable=True, is_of_type=str, values=[
                    'AccuracyMicro', 'AccuracyMacro', 'LogLoss', 'LogLossReduction'])
        if learners_selection_proportion is not None:
            self.settings['LearnersSelectionProportion'] = try_set(
                obj=learners_selection_proportion,
                none_acceptable=True,
                is_of_type=numbers.Real)
        if validation_dataset_proportion is not None:
            self.settings['ValidationDatasetProportion'] = try_set(
                obj=validation_dataset_proportion,
                none_acceptable=True,
                is_of_type=numbers.Real)

        super(
            ClassifierBestPerformanceSelector,
            self).__init__(
            name=self.name,
            settings=self.settings,
            kind=self.kind)
