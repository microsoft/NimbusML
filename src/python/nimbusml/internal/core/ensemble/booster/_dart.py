# --------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------------------------------------
# - Generated by tools/entrypoint_compiler.py: do not edit by hand
"""
Dart
"""

__all__ = ["Dart"]

import numbers

from ....utils.entrypoints import Component
from ....utils.utils import trace, try_set


class Dart(Component):
    """

    Dropouts meet Multiple Additive Regresion Trees.

    .. remarks::
        `Multiple Additive Regression Trees (MART)
        <https://arxiv.org/abs/1505.01866>`_ is an
        ensemble method of boosted regression trees. The Dropouts meet
        Multiple Additive Regression
    Trees (DART) employs dropouts in MART and overcomes the issues of over-
        specialization of MART,
    achiving better performance in many tasks.


        **Reference**

            `https://arxiv.org/abs/1505.01866
            <https://arxiv.org/abs/1505.01866>`_


    :param tree_drop_fraction: The drop ratio for trees. Range:(0,1).

    :param maximum_number_of_dropped_trees_per_round: Maximum number of dropped
        trees in a boosting round.

    :param skip_drop_fraction: Probability for not dropping in a boosting
        round.

    :param xgboost_dart_mode: True will enable xgboost dart mode.

    :param uniform_drop: True will enable uniform drop.

    :param minimum_split_gain: Minimum loss reduction required to make a
        further partition on a leaf node of the tree. the larger, the more
        conservative the algorithm will be.

    :param maximum_tree_depth: Maximum depth of a tree. 0 means no limit.
        However, tree still grows by best-first.

    :param minimum_child_weight: Minimum sum of instance weight(hessian) needed
        in a child. If the tree partition step results in a leaf node with the
        sum of instance weight less than min_child_weight, then the building
        process will give up further partitioning. In linear regression mode,
        this simply corresponds to minimum number of instances needed to be in
        each node. The larger, the more conservative the algorithm will be.

    :param subsample_frequency: Subsample frequency for bagging. 0 means no
        subsample. Specifies the frequency at which the bagging occurs, where
        if this is set to N, the subsampling will happen at every N
        iterations.This must be set with Subsample as this specifies the amount
        to subsample.

    :param subsample_fraction: Subsample ratio of the training instance.
        Setting it to 0.5 means that LightGBM randomly collected half of the
        data instances to grow trees and this will prevent overfitting. Range:
        (0,1].

    :param feature_fraction: Subsample ratio of columns when constructing each
        tree. Range: (0,1].

    :param l2_regularization: L2 regularization term on weights, increasing
        this value will make model more conservative.

    :param l1_regularization: L1 regularization term on weights, increase this
        value will make model more conservative.

    :param params: Additional arguments sent to compute engine.

    .. seealso::
        :py:func:`Gbdt <nimbusml.ensemble.booster.Gbdt>`,
        :py:func:`Goss <nimbusml.ensemble.booster.Goss>`,
        :py:func:`LightGbmBinaryClassifier
        <nimbusml.ensemble.LightGbmBinaryClassifier>`,
        :py:func:`LightGbmClassifier <nimbusml.ensemble.LightGbmClassifier>`,
        :py:func:`LightGbmRanker <nimbusml.ensemble.LightGbmRanker>`,
        :py:func:`LightGbmRegressor <nimbusml.ensemble.LightGbmRegressor>`

    .. index:: ensemble, booster

    Example:
       .. literalinclude:: /../nimbusml/examples/LightGbmClassifier.py
              :language: python
    """

    @trace
    def __init__(
            self,
            tree_drop_fraction=0.1,
            maximum_number_of_dropped_trees_per_round=1,
            skip_drop_fraction=0.5,
            xgboost_dart_mode=False,
            uniform_drop=False,
            minimum_split_gain=0.0,
            maximum_tree_depth=0,
            minimum_child_weight=0.1,
            subsample_frequency=0,
            subsample_fraction=1.0,
            feature_fraction=1.0,
            l2_regularization=0.01,
            l1_regularization=0.0,
            **params):

        self.tree_drop_fraction = tree_drop_fraction
        self.maximum_number_of_dropped_trees_per_round = maximum_number_of_dropped_trees_per_round
        self.skip_drop_fraction = skip_drop_fraction
        self.xgboost_dart_mode = xgboost_dart_mode
        self.uniform_drop = uniform_drop
        self.minimum_split_gain = minimum_split_gain
        self.maximum_tree_depth = maximum_tree_depth
        self.minimum_child_weight = minimum_child_weight
        self.subsample_frequency = subsample_frequency
        self.subsample_fraction = subsample_fraction
        self.feature_fraction = feature_fraction
        self.l2_regularization = l2_regularization
        self.l1_regularization = l1_regularization
        self.kind = 'BoosterParameterFunction'
        self.name = 'dart'
        self.settings = {}

        if tree_drop_fraction is not None:
            self.settings['TreeDropFraction'] = try_set(
                obj=tree_drop_fraction,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Inf': 0.0,
                    'Max': 1.0})
        if maximum_number_of_dropped_trees_per_round is not None:
            self.settings['MaximumNumberOfDroppedTreesPerRound'] = try_set(
                obj=maximum_number_of_dropped_trees_per_round,
                none_acceptable=True,
                is_of_type=numbers.Real, valid_range={'Inf': 0, 'Max': 2147483647})
        if skip_drop_fraction is not None:
            self.settings['SkipDropFraction'] = try_set(
                obj=skip_drop_fraction,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Inf': 0.0,
                    'Max': 1.0})
        if xgboost_dart_mode is not None:
            self.settings['XgboostDartMode'] = try_set(
                obj=xgboost_dart_mode, none_acceptable=True, is_of_type=bool)
        if uniform_drop is not None:
            self.settings['UniformDrop'] = try_set(
                obj=uniform_drop, none_acceptable=True, is_of_type=bool)
        if minimum_split_gain is not None:
            self.settings['MinimumSplitGain'] = try_set(
                obj=minimum_split_gain,
                none_acceptable=True,
                is_of_type=numbers.Real, valid_range={'Min': 0.0})
        if maximum_tree_depth is not None:
            self.settings['MaximumTreeDepth'] = try_set(
                obj=maximum_tree_depth,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Max': 2147483647,
                    'Min': 0})
        if minimum_child_weight is not None:
            self.settings['MinimumChildWeight'] = try_set(
                obj=minimum_child_weight,
                none_acceptable=True,
                is_of_type=numbers.Real, valid_range={'Min': 0.0})
        if subsample_frequency is not None:
            self.settings['SubsampleFrequency'] = try_set(
                obj=subsample_frequency,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Max': 2147483647,
                    'Min': 0})
        if subsample_fraction is not None:
            self.settings['SubsampleFraction'] = try_set(
                obj=subsample_fraction,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Inf': 0.0,
                    'Max': 1.0})
        if feature_fraction is not None:
            self.settings['FeatureFraction'] = try_set(
                obj=feature_fraction,
                none_acceptable=True,
                is_of_type=numbers.Real,
                valid_range={
                    'Inf': 0.0,
                    'Max': 1.0})
        if l2_regularization is not None:
            self.settings['L2Regularization'] = try_set(
                obj=l2_regularization,
                none_acceptable=True,
                is_of_type=numbers.Real, valid_range={'Min': 0.0})
        if l1_regularization is not None:
            self.settings['L1Regularization'] = try_set(
                obj=l1_regularization,
                none_acceptable=True,
                is_of_type=numbers.Real, valid_range={'Min': 0.0})

        super(
            Dart,
            self).__init__(
            name=self.name,
            settings=self.settings,
            kind=self.kind)
