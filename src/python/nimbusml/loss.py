# --------------------------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------------------------------------
# - Generated by tools/entrypoint_compiler.py: do not edit by hand


class Exp:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.


    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Exponential loss
        <https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
        for classification. Compared to :py:class:`Hinge
        <nimbusml.loss.Hinge>`, it penalizes more on the wrong prediction and
        has larger gradients. Its string name is ``'exp'``.

        It can be used for :py:class:`AveragedPerceptronBinaryClassifier
        <nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
        :py:class:`SgdBinaryClassifier
        <nimbusml.linear_model.SgdBinaryClassifier>`.

    :param beta: Dilation

    .. seealso::
        :py:class:`Log <nimbusml.loss.Log>`
        :py:class:`Hinge <nimbusml.loss.Hinge>`
        :py:class:`SmoothedHinge <nimbusml.loss.SmoothedHinge>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Exp.py
            :language: python

    .. index:: loss
    """

    def __init__(self, beta=1.0):
        self._params = {'beta': beta}
        self._string_name = 'exp'


class Hinge:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.



    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Hinge loss
        <https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
        for classification. Its string name is ``'hinge'``.

        It can be used for :py:class:`AveragedPerceptronBinaryClassifier
        <nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
        :py:class:`FastLinearBinaryClassifier
        <nimbusml.linear_model.FastLinearBinaryClassifier>`,
        :py:class:`FastLinearClassifier
        <nimbusml.linear_model.FastLinearClassifier>`,
        :py:class:`SgdBinaryClassifier
        <nimbusml.linear_model.SgdBinaryClassifier>`.

    :param margin: Margin value

    .. seealso::
        :py:class:`Exp <nimbusml.loss.Exp>`
        :py:class:`Log <nimbusml.loss.Log>`
        :py:class:`SmoothedHinge <nimbusml.loss.SmoothedHinge>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Hinge.py
            :language: python

    .. index:: loss
    """

    def __init__(self, margin=1.0):
        self._params = {'margin': margin}
        self._string_name = 'hinge'


class Log:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.


    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Log loss
        <https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
        for classification. Its string name is ``'log'``.

        It can be used for :py:class:`AveragedPerceptronBinaryClassifier
        <nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
        :py:class:`FastLinearBinaryClassifier
        <nimbusml.linear_model.FastLinearBinaryClassifier>`,
        :py:class:`FastLinearClassifier
        <nimbusml.linear_model.FastLinearClassifier>`,
        :py:class:`SgdBinaryClassifier
        <nimbusml.linear_model.SgdBinaryClassifier>`.

    .. seealso::
        :py:class:`Exp <nimbusml.loss.Exp>`
        :py:class:`Hinge <nimbusml.loss.Hinge>`
        :py:class:`SmoothedHinge <nimbusml.loss.SmoothedHinge>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Log.py
            :language: python


    .. index:: loss
    """

    def __init__(self):
        self._params = {}
        self._string_name = 'log'


class Poisson:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.

    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Poisson loss
        <https://en.wikipedia.org/wiki/Poisson_regression>`_ for
        regression.
        Assuming that the response variable y follows Poisson distribution,
        maximum likelihood is used to estimate the parameters by maximuzing
        the probability of obtaining the observed data. Its string name is
        ``'poisson'``.

        It can be used for :py:class:`OnlineGradientDescentRegressor
        <nimbusml.linear_model.OnlineGradientDescentRegressor>`.

    .. seealso::
        :py:class:`Squared <nimbusml.loss.Squared>`
        :py:class:`Tweedie <nimbusml.loss.Tweedie>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Poisson.py
            :language: python

    .. index:: loss
    """

    def __init__(self):
        self._params = {}
        self._string_name = 'poisson'


class SmoothedHinge:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.

    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Smoothed hinge loss
        <https://en.wikipedia.org/wiki/Loss_functions_for_classification>`_
        for classification. Its string name is ``'smoothed_hinge'``.

        It can be used for :py:class:`AveragedPerceptronBinaryClassifier
        <nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`,
        :py:class:`FastLinearBinaryClassifier
        <nimbusml.linear_model.FastLinearBinaryClassifier>`,
        :py:class:`FastLinearClassifier
        <nimbusml.linear_model.FastLinearClassifier>`,
        :py:class:`SgdBinaryClassifier
        <nimbusml.linear_model.SgdBinaryClassifier>`.

    :param smoothing_const: Smoothing constant

    .. seealso::
        :py:class:`Exp <nimbusml.loss.Exp>`
        :py:class:`Log <nimbusml.loss.Log>`
        :py:class:`Hinge <nimbusml.loss.Hinge>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/SmoothedHinge.py
            :language: python


    .. index:: loss
    """

    def __init__(self, smoothing_const=1.0):
        self._params = {'smoothing_const': smoothing_const}
        self._string_name = 'smoothed_hinge'


class Squared:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.


    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.
        The `Square loss
        <https://en.wikipedia.org/wiki/K-means_clustering>`_
        for regression.
        This loss calculates L2 loss, which is the square of the root mean
        square loss. Its string name is ``'squared'``.

        It can be used for :py:class:`FastLinearRegressor
        <nimbusml.linear_model.FastLinearRegressor>`,
        :py:class:`OnlineGradientDescentRegressor
        <nimbusml.linear_model.OnlineGradientDescentRegressor>`.

    .. seealso::
        :py:class:`Tweedie <nimbusml.loss.Tweedie>`
        :py:class:`Poisson <nimbusml.loss.Poisson>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Squared.py
            :language: python


    .. index:: loss
    """

    def __init__(self):
        self._params = {}
        self._string_name = 'squared'


class Tweedie:
    """
    Some of the trainers accept a loss parameter that will be used for
    training. It is also known as loss function, objective function, or
    optimization score function.

    .. remarks::
        Losses can be specified either as a string or a loss object. When
        loss is specified as one of these strings, the default values are
        used for the loss parameters. To change the default parameters, a
        loss object should be used, as seen in examples below.

        Each trainer supports only a subset of the losses mentioned above.
        To get the supported losses and the default loss, please refer to
        the documentation page for the specific trainer.

        The `Tweedie loss
        <https://en.wikipedia.org/wiki/Tweedie_distribution>`_ for
        regression. Assuming that the response variable y follows Tweedie
        distribution, maximum likelihood is used to estimate the parameters
        by maximuzing the probability of obtaining the observed data. Its
        string name is ``'tweedie'``.

        It can be used for :py:class:`OnlineGradientDescentRegressor
        <nimbusml.linear_model.OnlineGradientDescentRegressor>`.

    :param index: Index parameter for the Tweedie distribution, in the
        range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate
        values are compound Poisson loss.

    .. seealso::
        :py:class:`Squared <nimbusml.loss.Squared>`
        :py:class:`Poisson <nimbusml.loss.Poisson>`
        `API Guide: Loss Functions </nimbusml/apiguide#loss-functions>`_

    Example:
        .. literalinclude:: /../nimbusml/examples/Tweedie.py
            :language: python

    .. index:: loss
    """

    def __init__(self, index=1.5):
        self._params = {'index': index}
        self._string_name = 'tweedie'
