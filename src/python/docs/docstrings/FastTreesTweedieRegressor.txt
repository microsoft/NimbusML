    """

    Machine Learning Fast Tree

    .. remarks::
        Trains gradient boosted decision trees to fit target values using a
        Tweedie loss function. This learner is a generalization of Poisson,
        compound Poisson, and gamma regression.


        **Reference**
    
            `Wikipedia: Gradient boosting (Gradient tree boosting)
            <https://en.wikipedia.org/wiki/Gradient_boosting#Gradient_tree_boosting>`_
    
            `Greedy function approximation: A gradient boosting machine.
            <http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aos/1013203451>`_
    
    :param optimizer: Default is ``sgd``.

    :param normalize: Specifies the type of automatic normalization used:

        * ``"Auto"``: if normalization is needed, it is performed
          automatically. This is the default choice.
        * ``"No"``: no normalization is performed.
        * ``"Yes"``: normalization is performed.
        * ``"Warn"``: if normalization is needed, a warning
          message is displayed, but normalization is not performed.

        Normalization rescales disparate data ranges to a standard scale.
        Feature
        scaling insures the distances between data points are proportional
        and
        enables various optimization methods such as gradient descent to
        converge
        much faster. If normalization is performed, a ``MaxMin`` normalizer
        is
        used. It normalizes values in an interval [a, b] where ``-1 <= a <=
        0``
        and ``0 <= b <= 1`` and ``b - a = 1``. This normalizer preserves
        sparsity by mapping zero to zero.

    .. seealso::
        :py:func:`FastForestRegressor
        <nimbusml.ensemble.FastForestRegressor>`,
        :py:func:`FastTreesBinaryClassifier
        <nimbusml.ensemble.FastTreesBinaryClassifier>`,

    .. index:: models, regression

    Example:
       .. literalinclude:: /../nimbusml/examples/FastTreesTweedieRegressor.py
              :language: python

    """