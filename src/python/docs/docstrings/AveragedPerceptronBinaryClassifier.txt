    """

    Machine Learning Averaged Perceptron Binary Classifier

    .. remarks::
        Perceptron is a classification algorithm that makes its predictions
        based on a linear function. I.e., for an instance with feature values
        *f0, f1,..., f_D-1*, , the prediction is given by the sign of
        *sigma[0,D-1] ( w_i * f_i)*, where *w_0, w_1,...,w_D-1* are the
        weights
        computed by the algorithm.
        
        Perceptron is an online algorithm, i.e., it processes the instances
        in
        the training set one at a time. The weights are initialized to be 0,
        or
        some random values. Then, for each example in the training set, the
        value of *sigma[0, D-1] (w_i * f_i)* is computed. If this value has
        the
        same sign as the label of the current example, the weights remain the
        same. If they have opposite signs, the weights vector is updated by
        either subtracting or adding (if the label is negative or positive,
        respectively) the feature vector of the current example, multiplied
        by a
        factor *0 < a <= 1*, called the learning rate. In a generalization of
        this algorithm, the weights are updated by adding the feature vector
        multiplied by the learning rate, and by the gradient of some loss
        function (in the specific case described above, the loss is hinge-
        loss,
        whose gradient is 1 when it is non-zero).

        In Averaged Perceptron (AKA voted-perceptron), the weight vectors are
        stored, together with a weight that counts the number of iterations
        it
        survived (this is equivalent to storing the weight vector after every
        iteration, regardless of whether it was updated or not). The
        prediction
        is then calculated by taking the weighted average of all the sums
        *sigma[0, D-1] (w_i * f_i)* or the different weight vectors.


        **Reference**
    
            `Wikipedia entry for Perceptron
            <https://en.wikipedia.org/wiki/Perceptron>`_
    
            `Large Margin Classification Using the Perceptron Algorithm
            <https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.48.8200>`_
            
            `Discriminative Training Methods for Hidden Markov Models
            <https://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.6725>`_
    

    :param loss: The default is :py:class:`'hinge' <nimbusml.loss.Hinge>`. Other
        choices are :py:class:`'exp' <nimbusml.loss.Exp>`, :py:class:`'log'
        <nimbusml.loss.Log>`, and :py:class:`'smoothed_hinge'
        <nimbusml.loss.SmoothedHinge>`. For more information, please see the
        documentation page about losses, [Loss](xref:nimbusml.loss).
		
    :param normalize: Specifies the type of automatic normalization used:

        * ``"Auto"``: if normalization is needed, it is performed
          automatically. This is the default choice.
        * ``"No"``: no normalization is performed.
        * ``"Yes"``: normalization is performed.
        * ``"Warn"``: if normalization is needed, a warning
          message is displayed, but normalization is not performed.

        Normalization rescales disparate data ranges to a standard scale.
        Feature
        scaling insures the distances between data points are proportional
        and
        enables various optimization methods such as gradient descent to
        converge
        much faster. If normalization is performed, a ``MaxMin`` normalizer
        is
        used. It normalizes values in an interval [a, b] where ``-1 <= a <=
        0``
        and ``0 <= b <= 1`` and ``b - a = 1``. This normalizer preserves
        sparsity by mapping zero to zero.

    .. seealso::
        :py:func:`LogisticRegressionClassifier
        <nimbusml.linear_model.LogisticRegressionClassifier>`,
        `Types </nimbusml/concepts/types#column-types>`_

    .. index:: models, classification, perceptron

    Example:
       .. literalinclude:: /../nimbusml/examples/AveragedPerceptronBinaryClassifier.py
               :language: python
    """
