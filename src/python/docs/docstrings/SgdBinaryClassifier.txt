    """

    Machine Learning Hogwild Stochastic Gradient Descent Binary
    Classifier

    .. remarks::
        The Stochastic Gradient Descent (SGD) is one of the most popular
        stochastic optimization procedure that can be integrated into several
        machine learning tasks to achieve state-of-the-art performance. The
        Hogwild SGD binary classification learner implements SGD for binary
        classification that supports multi-threading without any locking. If
        the
        associated optimization problem is sparse, then Hogwild SGD achieves
        a
        nearly optimal rate of convergence. For a detailed reference, please
        refer to `http://arxiv.org/pdf/1106.5730v2.pdf
        <http://arxiv.org/pdf/1106.5730v2.pdf>`_.


        **Reference**
    
            `http://arxiv.org/pdf/1106.5730v2.pdf
            <http://arxiv.org/pdf/1106.5730v2.pdf>`_
    

    :param normalize: Specifies the type of automatic normalization used:

        * ``"Auto"``: if normalization is needed, it is performed
          automatically. This is the default choice.
        * ``"No"``: no normalization is performed.
        * ``"Yes"``: normalization is performed.
        * ``"Warn"``: if normalization is needed, a warning
          message is displayed, but normalization is not performed.

        Normalization rescales disparate data ranges to a standard scale.
        Feature
        scaling insures the distances between data points are proportional
        and
        enables various optimization methods such as gradient descent to
        converge
        much faster. If normalization is performed, a ``MaxMin`` normalizer
        is
        used. It normalizes values in an interval [a, b] where ``-1 <= a <=
        0``
        and ``0 <= b <= 1`` and ``b - a = 1``. This normalizer preserves
        sparsity by mapping zero to zero.

    :param loss: The default is :py:class:`'log' <nimbusml.loss.Log>`. Other
        choices are :py:class:`'exp' <nimbusml.loss.Exp>`, :py:class:`'hinge'
        <nimbusml.loss.Hinge>`, and :py:class:`'smoothed_hinge'
        <nimbusml.loss.SmoothedHinge>`. For more information, please see the
        documentation page about losses, [Loss](xref:nimbusml.loss).

    .. seealso::
        :py:func:`LogisticRegressionClassifier
        <nimbusml.linear_model.LogisticRegressionClassifier>`,
        :py:func:`AveragedPerceptronBinaryClassifier
        <nimbusml.linear_model.AveragedPerceptronBinaryClassifier>`

    .. index:: models, classification, stocastic, gradient, descent

    Example:
       .. literalinclude:: /../nimbusml/examples/SgdBinaryClassifier.py
              :language: python
    """